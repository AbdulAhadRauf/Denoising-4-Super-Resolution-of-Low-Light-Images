{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 97753,
          "databundleVersionId": 11639668,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "ntbk 1",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "tRuRFrZMmuQH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "dlp_jan_2025_nppe_3_path = kagglehub.competition_download('dlp-jan-2025-nppe-3')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "UU_XZ7AjmuQS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    #for filename in filenames:\n",
        "        #print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T14:10:59.174053Z",
          "iopub.execute_input": "2025-04-07T14:10:59.1744Z",
          "iopub.status.idle": "2025-04-07T14:10:59.494348Z",
          "shell.execute_reply.started": "2025-04-07T14:10:59.17437Z",
          "shell.execute_reply": "2025-04-07T14:10:59.493457Z"
        },
        "id": "tkRl3XSMmuQU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_images_from_dlp_competition(noisy_dir, gt_dir):\n",
        "    noisy_images = []\n",
        "    clean_images = []\n",
        "    image_ids = []\n",
        "\n",
        "    # Sort to ensure alignment\n",
        "    noisy_filenames = sorted(os.listdir(noisy_dir))\n",
        "    gt_filenames = sorted(os.listdir(gt_dir))\n",
        "\n",
        "    for noisy_name, gt_name in zip(noisy_filenames, gt_filenames):\n",
        "        noisy_path = os.path.join(noisy_dir, noisy_name)\n",
        "        gt_path = os.path.join(gt_dir, gt_name)\n",
        "\n",
        "        # Load both images\n",
        "        noisy_img = Image.open(noisy_path).convert('RGB')\n",
        "        gt_img = Image.open(gt_path).convert('RGB')\n",
        "\n",
        "        # Convert to NumPy arrays\n",
        "        noisy_array = np.array(noisy_img)\n",
        "        gt_array = np.array(gt_img)\n",
        "\n",
        "        noisy_images.append(noisy_array)\n",
        "        clean_images.append(gt_array)\n",
        "        image_ids.append(noisy_name)\n",
        "\n",
        "    return np.array(noisy_images), np.array(clean_images), image_ids\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T14:10:59.495772Z",
          "iopub.execute_input": "2025-04-07T14:10:59.496163Z",
          "iopub.status.idle": "2025-04-07T14:10:59.502087Z",
          "shell.execute_reply.started": "2025-04-07T14:10:59.496141Z",
          "shell.execute_reply": "2025-04-07T14:10:59.501175Z"
        },
        "id": "ufYFYwYGmuQV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "###EDA\n",
        "train_noisy_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/train'\n",
        "train_gt_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/train/gt'\n",
        "\n",
        "val_noisy_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/val'   # path to noisy low-res images\n",
        "val_gt_folder = '/kaggle/input/dlp-jan-2025-nppe-3/archive/val/gt'         # path to clean high-res ground truth images\n",
        "\n",
        "noisy_imgs, clean_imgs, ids = load_images_from_dlp_competition(train_noisy_folder, train_gt_folder)\n",
        "val_noisy_imgs, val_clean_imgs, ids = load_images_from_dlp_competition(val_noisy_folder, val_gt_folder)\n",
        "\n",
        "print(f\"Loaded train {len(noisy_imgs)} image pairs.\")\n",
        "print(f\"Val Noisy image shape: {noisy_imgs[0].shape}, Ground truth shape: {clean_imgs[0].shape}\")\n",
        "\n",
        "print(f\"Loaded Val {len(val_noisy_imgs)} image pairs.\")\n",
        "print(f\"Val Noisy image shape: {val_noisy_imgs[0].shape}, Ground truth shape: {val_clean_imgs[0].shape}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T14:10:59.503113Z",
          "iopub.execute_input": "2025-04-07T14:10:59.503347Z"
        },
        "id": "v5DN00A4muQX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_sample_pairs(noisy_imgs, clean_imgs, image_ids, n=3):\n",
        "    plt.figure(figsize=(12, 4 * n))\n",
        "    for i in range(n):\n",
        "        # Noisy\n",
        "        plt.subplot(n, 2, 2*i + 1)\n",
        "        plt.imshow(noisy_imgs[i])\n",
        "        plt.title(f\"Noisy Image: {image_ids[i]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ground Truth\n",
        "        plt.subplot(n, 2, 2*i + 2)\n",
        "        plt.imshow(clean_imgs[i])\n",
        "        plt.title(\"Ground Truth\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_sample_pairs(noisy_imgs, clean_imgs, ids)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "OBmVnfChmuQY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plot_intensity_comparison(noisy_img, clean_img):\n",
        "    noisy_gray = np.array(Image.fromarray(noisy_img).convert('L')).flatten()\n",
        "    clean_gray = np.array(Image.fromarray(clean_img).convert('L')).flatten()\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.histplot(noisy_gray, label='Noisy', color='orange', kde=True)\n",
        "    sns.histplot(clean_gray, label='Ground Truth', color='blue', kde=True)\n",
        "    plt.title(\"Pixel Intensity Distribution (Grayscale)\")\n",
        "    plt.xlabel(\"Pixel Value\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_intensity_comparison(noisy_imgs[0], clean_imgs[0])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QM4OPP9VmuQZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_images(imgs, label):\n",
        "    imgs_flat = imgs.astype(np.float32).reshape(len(imgs), -1)\n",
        "    print(f\"--- {label} Image Stats ---\")\n",
        "    print(\"Mean:\", np.mean(imgs_flat))\n",
        "    print(\"Std Dev:\", np.std(imgs_flat))\n",
        "    print(\"Min:\", np.min(imgs_flat))\n",
        "    print(\"Max:\", np.max(imgs_flat))\n",
        "    print()\n",
        "\n",
        "summarize_images(noisy_imgs, \"Noisy\")\n",
        "summarize_images(clean_imgs, \"Ground Truth\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "UXGQR6o8muQb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_noise_map(noisy, clean):\n",
        "    noisy_resized = np.array(Image.fromarray(noisy).resize(clean.shape[1::-1], Image.BICUBIC))\n",
        "    diff = np.abs(noisy_resized.astype(int) - clean.astype(int))\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(noisy_resized)\n",
        "    plt.title(\"Upscaled Noisy\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(clean)\n",
        "    plt.title(\"Ground Truth\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(diff)\n",
        "    plt.title(\"Difference Map\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_noise_map(noisy_imgs[0], clean_imgs[0])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KhwAlrmfmuQc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import cv2\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    mse = np.mean((img1.astype(np.float32) - img2.astype(np.float32)) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    PIXEL_MAX = 255.0\n",
        "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "\n",
        "# Example:\n",
        "noisy_upscaled = np.array(Image.fromarray(noisy_imgs[0]).resize(clean_imgs[0].shape[1::-1], Image.BICUBIC))\n",
        "psnr_value = calculate_psnr(noisy_upscaled, clean_imgs[0])\n",
        "print(f\"PSNR between upscaled noisy and ground truth: {psnr_value:.2f} dB\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "cqyAhFb2muQe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_noisy= noisy_imgs\n",
        "train_gt =clean_imgs\n",
        "\n",
        "val_noisy= val_noisy_imgs\n",
        "val_gt= val_clean_imgs"
      ],
      "metadata": {
        "trusted": true,
        "id": "VhZi6oqsmuQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, Compose\n",
        "\n",
        "transform = Compose([ToTensor()])\n",
        "\n",
        "class DLPDataset(Dataset):\n",
        "    def __init__(self, noisy_imgs, clean_imgs):\n",
        "        self.noisy_imgs = noisy_imgs\n",
        "        self.clean_imgs = clean_imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy = transform(Image.fromarray(self.noisy_imgs[idx])) * 255.0\n",
        "        clean = transform(Image.fromarray(self.clean_imgs[idx])) * 255.0\n",
        "        return noisy, clean\n",
        "\n",
        "train_dataset = DLPDataset(train_noisy, train_gt)\n",
        "val_dataset = DLPDataset(val_noisy, val_gt)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "rZoc_8DAmuQi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "def calculate_batch_psnr(output, target):\n",
        "    mse = F.mse_loss(output, target, reduction='none')\n",
        "    mse = mse.view(mse.size(0), -1).mean(dim=1)\n",
        "    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
        "    return psnr.mean().item()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "vazQmbK4muQj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth=1 https://github.com/sanghyun-son/EDSR-PyTorch.git"
      ],
      "metadata": {
        "trusted": true,
        "id": "gUnxmbXYmuQk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if EDSR-PyTorch was cloned\n",
        "print(\"EDSR-PyTorch\" in os.listdir())"
      ],
      "metadata": {
        "trusted": true,
        "id": "DxQ8rThpmuQk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory into the repo\n",
        "os.chdir(\"EDSR-PyTorch\")\n",
        "\n",
        "# List contents to verify\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "nNUnaxiXmuQl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./src')  # Not 'code', it's 'src'"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZfnV2yTxmuQl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('./src'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "cF__qaIRmuQl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Step 1: Prevent argparse from picking up unwanted notebook args\n",
        "sys.argv = ['']  # ðŸ›‘ Clear CLI args before importing\n",
        "\n",
        "# Step 2: Add src directory to path\n",
        "sys.path.append('./src')\n",
        "\n",
        "# Step 3: Import EDSR and args safely\n",
        "from model.edsr import EDSR\n",
        "from option import args  # No more SystemExit!\n",
        "\n",
        "# Step 4: Customize args\n",
        "args.scale = [4]\n",
        "args.n_resblocks = 8\n",
        "args.n_feats = 64\n",
        "args.rgb_range = 255\n",
        "args.res_scale = 1\n",
        "args.n_colors = 3\n",
        "\n",
        "# Step 5: Create the model\n",
        "model = EDSR(args).cuda()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pdiP9ECCmuQm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# Setup\n",
        "model = EDSR(args).cuda()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Halve LR every 5 epochs\n",
        "\n",
        "best_psnr = 0\n",
        "save_path = \"best_model.pth\"\n",
        "\n",
        "def calculate_psnr(pred, target, max_val=255.0):\n",
        "    mse = nn.functional.mse_loss(pred, target)\n",
        "    psnr = 20 * torch.log10(max_val / torch.sqrt(mse + 1e-8))\n",
        "    return psnr.item()\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 20\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
        "\n",
        "    for noisy, clean in loop:\n",
        "        noisy = noisy.cuda()\n",
        "        clean = clean.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast(\"cuda\"):  # AMP-enabled\n",
        "            output = model(noisy)\n",
        "\n",
        "            # Debug: check output range\n",
        "            if torch.any(torch.isnan(output)) or torch.any(torch.isinf(output)):\n",
        "                print(\"âš ï¸ NaN or Inf in model output!\")\n",
        "\n",
        "            # Optional: clamp output values\n",
        "            # output = torch.clamp(output, 0, 255)\n",
        "\n",
        "            loss = criterion(output, clean)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"[Epoch {epoch+1}] Training Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_psnr = 0\n",
        "    with torch.no_grad():\n",
        "        for noisy, clean in tqdm(val_loader, desc=\"Validating\"):\n",
        "            noisy = noisy.cuda()\n",
        "            clean = clean.cuda()\n",
        "            output = model(noisy)\n",
        "            val_psnr += calculate_psnr(output, clean)\n",
        "\n",
        "    val_psnr /= len(val_loader)\n",
        "    print(f\"[Epoch {epoch+1}] Validation PSNR: {val_psnr:.2f} dB\")\n",
        "\n",
        "    if val_psnr > best_psnr:\n",
        "        best_psnr = val_psnr\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"âœ… Saved new best model with PSNR: {best_psnr:.2f} dB\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "print(\"ðŸ” Loaded best model for inference.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9YLqB91jmuQn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "trusted": true,
        "id": "IWtG1bramuQo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/kaggle/input/dlp-jan-2025-nppe-3/archive/test/test_00001.png'\n",
        "\n",
        "# Open and check the image size\n",
        "with Image.open(image_path) as img:\n",
        "    print(\"Image size:\", img.size)  # (width, height)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "gwzr2Bp-muQp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_test_images(test_folder):\n",
        "    filenames = sorted(os.listdir(test_folder))\n",
        "    images = []\n",
        "\n",
        "    for fname in filenames:\n",
        "        img_path = os.path.join(test_folder, fname)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        images.append(np.array(img))\n",
        "\n",
        "    return images, filenames\n",
        "\n",
        "test_folder = \"/kaggle/input/dlp-jan-2025-nppe-3/archive/test\"\n",
        "test_images, test_filenames = load_test_images(test_folder)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "lrAlG9hXmuQp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        self.images = images\n",
        "        self.transform = ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.transform(Image.fromarray(self.images[idx])) * 255.0\n",
        "        return img\n",
        "\n",
        "test_dataset = TestDataset(test_images)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "FuQaNFB7muQq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "trusted": true,
        "id": "Uo5KBfgImuQq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToPILImage\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "to_pil = ToPILImage()\n",
        "\n",
        "with torch.no_grad():\n",
        "    idx = 0\n",
        "    for batch in test_loader:\n",
        "        batch = batch.cuda()\n",
        "        preds = model(batch).clamp(0, 255)\n",
        "\n",
        "        for i in range(preds.size(0)):\n",
        "            img = to_pil(preds[i].cpu() / 255.0)  # Scale [0,255] â†’ [0,1] for PIL\n",
        "            out_name = test_filenames[idx].replace(\".jpg\", \".png\")  # match your original\n",
        "            img.save(f\"outputs/{out_name}\")\n",
        "            idx += 1\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "hpqAT9JZmuQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def images_to_csv(folder_path, output_csv):\n",
        "    data_rows = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path).convert('L')\n",
        "            image_array = np.array(image).flatten()[::8]\n",
        "            # Replace 'test_' with 'gt_' in the ID\n",
        "            image_id = filename.split('.')[0].replace('test_', 'gt_')\n",
        "            data_rows.append([image_id, *image_array])\n",
        "    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n",
        "    df = pd.DataFrame(data_rows, columns=column_names)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f'Successfully saved to {output_csv}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZBzzcq4dmuQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = 'outputs'\n",
        "output_csv = '/kaggle/working/submission.csv'\n",
        "images_to_csv(folder_path, output_csv)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nYUwHrtzmuQr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load submission.csv\n",
        "submission_df = pd.read_csv('/kaggle/working/submission.csv')\n",
        "\n",
        "# Show basic info\n",
        "print(submission_df.info())\n",
        "\n",
        "# Show first few rows\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "FsHLZJnomuQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load submission CSV\n",
        "df = submission_df\n",
        "\n",
        "# Basic Info\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns[:10], \"...\")  # Show some column names\n",
        "print(\"Sample IDs:\", df['ID'].head().tolist())\n",
        "\n",
        "# Check pixel value range\n",
        "pixel_columns = df.columns[1:]\n",
        "all_pixels = df[pixel_columns].values.flatten()\n",
        "print(\"Pixel stats â†’ Min:\", np.min(all_pixels), \"Max:\", np.max(all_pixels), \"Mean:\", np.mean(all_pixels))\n",
        "\n",
        "# Plot a few sample images\n",
        "def plot_sample_images(df, num_images=4):\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for i in range(num_images):\n",
        "        img_data = df.iloc[i, 1:].values.astype(np.uint8)\n",
        "        # Reshape to known size: (640, 1024) â†’ (2560, 4096) before downsampling ::8 â†’ back to 640x1024 // 8 = 81920\n",
        "        img = img_data.reshape(256, 320)  # 256*320 = 81920\n",
        "        axs[i].imshow(img, cmap='gray')\n",
        "        axs[i].set_title(df.iloc[i, 0])\n",
        "        axs[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_sample_images(df)\n",
        "\n",
        "# Histogram of pixel intensities\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(all_pixels, bins=50, color='steelblue', edgecolor='black')\n",
        "plt.title(\"Pixel Intensity Distribution\")\n",
        "plt.xlabel(\"Pixel Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "X0FFjF8MmuQs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "###using esrgan"
      ],
      "metadata": {
        "trusted": true,
        "id": "wbuftMcamuQt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/kaggle/working/EDSR-PyTorch/outputs/test_00001.png'\n",
        "\n",
        "# Open and check the image size\n",
        "with Image.open(image_path) as img:\n",
        "    print(\"Image size:\", img.size)  # (width, height)"
      ],
      "metadata": {
        "trusted": true,
        "id": "s_KijTadmuQu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /kaggle/working\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "R8Hx1LIbmuQu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Real-ESRGAN\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "FgIiTBMRmuQv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/xinntao/Real-ESRGAN\n",
        "%cd Real-ESRGAN\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "CARincQpmuQw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr facexlib gfpgan\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "V3yrz7Z-muQx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "trusted": true,
        "id": "6v2b6MURmuQy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "trusted": true,
        "id": "uwUbblc7muQy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls scripts\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "xK9tmx66muQy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p experiments/pretrained_models\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "jL0nSK80muQ7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/lllyasviel/Annotators/resolve/main/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "3vVi8LHQmuQ8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "zfZgLjcTmuQ8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_wwHL-7RmuQ8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_realesrgan.py \\\n",
        "-n RealESRGAN_x4plus \\\n",
        "-i /kaggle/working/EDSR-PyTorch/outputs\\\n",
        "--face_enhance\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "RlBkEUlVmuQ9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -type f -name \"*.png\"\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ruva5A9GmuQ9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Path to the image\n",
        "image_path = './results/test_00020_out.png'\n",
        "\n",
        "# Open and check the image size\n",
        "with Image.open(image_path) as img:\n",
        "    print(\"Image size:\", img.size)  # (width, height)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wYiHIhSymuQ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def images_to_csv(folder_path, output_csv):\n",
        "    data_rows = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path).convert('L')\n",
        "            image_array = np.array(image).flatten()[::8]\n",
        "            # Replace 'test_' with 'gt_' in the ID\n",
        "            image_id = filename.split('.')[0].replace('test_', 'gt_')\n",
        "            data_rows.append([image_id, *image_array])\n",
        "    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n",
        "    df = pd.DataFrame(data_rows, columns=column_names)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f'Successfully saved to {output_csv}')\n",
        "'''"
      ],
      "metadata": {
        "trusted": true,
        "id": "sBcii4YPmuQ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "def images_to_csv1(folder_path, output_csv):\n",
        "    data_rows = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path).convert('L').resize((1024, 640))\n",
        "            image_array = np.array(image).flatten()[::8]\n",
        "\n",
        "            # Extract ID from something like 'test_00043_out.png'\n",
        "            base = os.path.splitext(filename)[0]  # test_00043_out\n",
        "            parts = base.split('_')               # ['test', '00043', 'out']\n",
        "            if len(parts) >= 2:\n",
        "                image_id = f\"gt_{parts[1]}\"       # gt_00043\n",
        "            else:\n",
        "                image_id = base                   # fallback if unexpected format\n",
        "\n",
        "            data_rows.append([image_id, *image_array])\n",
        "\n",
        "    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n",
        "    df = pd.DataFrame(data_rows, columns=column_names)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f'Successfully saved to {output_csv}')\n",
        "\n",
        "# Call the function\n",
        "folder_path = './results/'\n",
        "output_csv = '/kaggle/working/submission_1.csv'\n",
        "images_to_csv1(folder_path, output_csv)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KUpe8teEmuQ_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load submission.csv\n",
        "submission_df = pd.read_csv('/kaggle/working/submission_1.csv')\n",
        "\n",
        "# Show basic info\n",
        "print(submission_df.info())\n",
        "\n",
        "# Show first few rows\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ipNFp2pLmuRB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load submission CSV\n",
        "df = submission_df\n",
        "\n",
        "# Basic Info\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns[:10], \"...\")  # Show some column names\n",
        "print(\"Sample IDs:\", df['ID'].head().tolist())\n",
        "\n",
        "# Check pixel value range\n",
        "pixel_columns = df.columns[1:]\n",
        "all_pixels = df[pixel_columns].values.flatten()\n",
        "print(\"Pixel stats â†’ Min:\", np.min(all_pixels), \"Max:\", np.max(all_pixels), \"Mean:\", np.mean(all_pixels))\n",
        "\n",
        "# Plot a few sample images\n",
        "def plot_sample_images(df, num_images=4):\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for i in range(num_images):\n",
        "        img_data = df.iloc[i, 1:].values.astype(np.uint8)\n",
        "        # Reshape to known size: (640, 1024) â†’ (2560, 4096) before downsampling ::8 â†’ back to 640x1024 // 8 = 81920\n",
        "        img = img_data.reshape(256, 320)  # 256*320 = 81920\n",
        "        axs[i].imshow(img, cmap='gray')\n",
        "        axs[i].set_title(df.iloc[i, 0])\n",
        "        axs[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_sample_images(df)\n",
        "\n",
        "# Histogram of pixel intensities\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(all_pixels, bins=50, color='steelblue', edgecolor='black')\n",
        "plt.title(\"Pixel Intensity Distribution\")\n",
        "plt.xlabel(\"Pixel Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "L_3buLcZmuRC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "###Using swinIR"
      ],
      "metadata": {
        "trusted": true,
        "id": "z_kOBJbTmuRD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JingyunLiang/SwinIR.git\n",
        "%cd SwinIR"
      ],
      "metadata": {
        "trusted": true,
        "id": "HCbGELa_muRD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p experiments/pretrained_models\n",
        "\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/004_grayDN_DFWB_s128w8_SwinIR-M_noise15.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/004_grayDN_DFWB_s128w8_SwinIR-M_noise25.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/004_grayDN_DFWB_s128w8_SwinIR-M_noise50.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise15.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise25.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise50.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg10.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg20.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg30.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_CAR_DFWB_s126w7_SwinIR-M_jpeg40.pth -P experiments/pretrained_models\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "bdpI0Ws3muRD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls experiments/pretrained_models"
      ],
      "metadata": {
        "trusted": true,
        "id": "8sX8KtglmuRE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Resize, Compose, Grayscale, ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "transform = Compose([\n",
        "    Grayscale(num_output_channels=1),\n",
        "    Resize((128, 128)),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "class DLPDataset1(Dataset):\n",
        "    def __init__(self, noisy_imgs, clean_imgs):\n",
        "        self.noisy_imgs = noisy_imgs\n",
        "        self.clean_imgs = clean_imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy = transform(Image.fromarray(self.noisy_imgs[idx])) * 255.0\n",
        "        clean = transform(Image.fromarray(self.clean_imgs[idx])) * 255.0\n",
        "        return noisy, clean\n",
        "\n",
        "train_dataset = DLPDataset1(train_noisy, train_gt)\n",
        "val_dataset = DLPDataset1(val_noisy, val_gt)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_UVnZwPomuRF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr"
      ],
      "metadata": {
        "trusted": true,
        "id": "RHk5_Z5amuRF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NykHoBfMmuRG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from basicsr.archs.swinir_arch import SwinIR\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = SwinIR(\n",
        "    upscale=1,\n",
        "    in_chans=1,\n",
        "    img_size=128,  # adjust if your patch size is different\n",
        "    window_size=8,\n",
        "    img_range=255.0,\n",
        "    depths=[6, 6, 6, 6, 6, 6],\n",
        "    embed_dim=180,\n",
        "    num_heads=[6, 6, 6, 6, 6, 6],\n",
        "    mlp_ratio=2,\n",
        "    upsampler='',  # for denoising\n",
        "    resi_connection='1conv'\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "trusted": true,
        "id": "DDKQScJAmuRG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for noisy, clean in tqdm(dataloader, desc=\"Training\"):\n",
        "        noisy, clean = noisy.to(device), clean.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(noisy)\n",
        "        loss = criterion(output, clean)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_psnr = 0.0\n",
        "    total_ssim = 0.0\n",
        "    torch.cuda.empty_cache()  # â† clear unused memory\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for noisy, clean in tqdm(dataloader, desc=\"Validating\"):\n",
        "            noisy, clean = noisy.to(device), clean.to(device)\n",
        "            output = model(noisy)\n",
        "\n",
        "            loss = criterion(output, clean)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            output_np = output.cpu().numpy()\n",
        "            clean_np = clean.cpu().numpy()\n",
        "\n",
        "            # Loop over batch\n",
        "            for i in range(output_np.shape[0]):\n",
        "                out_img = np.squeeze(output_np[i])\n",
        "                gt_img = np.squeeze(clean_np[i])\n",
        "\n",
        "                psnr = compare_psnr(gt_img, out_img, data_range=255.0)\n",
        "                ssim = compare_ssim(gt_img, out_img, data_range=255.0)\n",
        "\n",
        "                total_psnr += psnr\n",
        "                total_ssim += ssim\n",
        "\n",
        "    n = len(dataloader.dataset)\n",
        "    return (\n",
        "        total_loss / len(dataloader),\n",
        "        total_psnr / n,\n",
        "        total_ssim / n\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_4HQpOGsmuRH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_psnr = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_psnr, val_ssim = validate(model, val_loader, criterion)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | PSNR: {val_psnr:.2f} | SSIM: {val_ssim:.4f}\")\n",
        "\n",
        "    if val_psnr > best_psnr:\n",
        "        best_psnr = val_psnr\n",
        "        torch.save(model.state_dict(), f\"best_swinir_psnr_{best_psnr:.2f}.pth\")\n",
        "        print(f\"âœ… Saved new best model at Epoch {epoch+1} with PSNR: {val_psnr:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NC2H1r8wmuRI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "###inference\n",
        "from torchvision.transforms import Resize, Compose, Grayscale, ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "test_transform = Compose([\n",
        "    Grayscale(num_output_channels=1),\n",
        "    Resize((1024, 640)),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, noisy_imgs):\n",
        "        self.noisy_imgs = noisy_imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        noisy = test_transform(Image.fromarray(self.noisy_imgs[idx])) * 255.0\n",
        "        return noisy\n",
        "\n",
        "test_images, test_filenames = load_test_images(test_folder)\n",
        "\n",
        "test_dataset = TestDataset(test_images)  # not test_noisy\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "kstzguhumuRJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToPILImage\n",
        "import torch\n",
        "\n",
        "# --- Load best model ---\n",
        "model.load_state_dict(torch.load(\"/kaggle/working/SwinIR/best_swinir_psnr_43.99.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# --- Inference & Save ---\n",
        "os.makedirs(\"outputs1\", exist_ok=True)\n",
        "to_pil = ToPILImage()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, batch in enumerate(test_loader):\n",
        "        batch = batch.cuda()\n",
        "        preds = model(batch).clamp(0, 255)\n",
        "\n",
        "        # Convert tensor to image and save\n",
        "        img = to_pil(preds[0].cpu() / 255.0)  # Normalize for PIL\n",
        "        out_name = test_filenames[idx].rsplit(\".\", 1)[0] + \".png\"\n",
        "        img.save(f\"outputs1/{out_name}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "gVD8Gg-lmuRJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/kaggle/working/SwinIR/outputs1/test_00001.png'\n",
        "\n",
        "# Open and check the image size\n",
        "with Image.open(image_path) as img:\n",
        "    print(\"Image size:\", img.size)  # (width, height)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QPLDA2BomuRK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "def images_to_csv3(folder_path, output_csv):\n",
        "    data_rows = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path).convert('L').resize((1024, 640))\n",
        "            image_array = np.array(image).flatten()[::8]  # downsample\n",
        "\n",
        "            # Extract ID from something like 'test_00043_SwinIR.png'\n",
        "            base = os.path.splitext(filename)[0]      # test_00043_SwinIR\n",
        "            parts = base.split('_')                   # ['test', '00043', 'SwinIR']\n",
        "            if len(parts) >= 2 and parts[1].isdigit():\n",
        "                image_id = f\"gt_{parts[1]}\"           # gt_00043\n",
        "            else:\n",
        "                image_id = base\n",
        "\n",
        "            data_rows.append([image_id, *image_array])\n",
        "\n",
        "    if not data_rows:\n",
        "        print(\"No valid images found.\")\n",
        "        return\n",
        "\n",
        "    column_names = ['ID'] + [f'pixel_{i}' for i in range(len(data_rows[0]) - 1)]\n",
        "    df = pd.DataFrame(data_rows, columns=column_names)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f'Successfully saved to {output_csv}')\n",
        "\n",
        "# Call the function\n",
        "folder_path = '/kaggle/working/SwinIR/outputs1'\n",
        "output_csv = '/kaggle/working/submission_3.csv'\n",
        "images_to_csv3(folder_path, output_csv)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NYEzD60HmuRK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load submission.csv\n",
        "submission_df = pd.read_csv('/kaggle/working/submission_3.csv')\n",
        "\n",
        "# Show basic info\n",
        "print(submission_df.info())\n",
        "\n",
        "# Show first few rows\n",
        "submission_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PW-UzWPLmuRL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('/kaggle/working/submission_3.csv')\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"/kaggle/working/submission.zip\", 'w') as zipf:\n",
        "    zipf.write(\"/kaggle/working/submission_3.csv\", arcname=\"submission_3.csv\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "sqiBFmt1muRL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load submission CSV\n",
        "df = submission_df\n",
        "\n",
        "# Basic Info\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns[:10], \"...\")  # Show some column names\n",
        "print(\"Sample IDs:\", df['ID'].head().tolist())\n",
        "\n",
        "# Check pixel value range\n",
        "pixel_columns = df.columns[1:]\n",
        "all_pixels = df[pixel_columns].values.flatten()\n",
        "print(\"Pixel stats â†’ Min:\", np.min(all_pixels), \"Max:\", np.max(all_pixels), \"Mean:\", np.mean(all_pixels))\n",
        "\n",
        "# Plot a few sample images\n",
        "def plot_sample_images(df, num_images=4):\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for i in range(num_images):\n",
        "        img_data = df.iloc[i, 1:].values.astype(np.uint8)\n",
        "        # Reshape to known size: (640, 1024) â†’ (2560, 4096) before downsampling ::8 â†’ back to 640x1024 // 8 = 81920\n",
        "        img = img_data.reshape(256, 320)  # 256*320 = 81920\n",
        "        axs[i].imshow(img, cmap='gray')\n",
        "        axs[i].set_title(df.iloc[i, 0])\n",
        "        axs[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_sample_images(df)\n",
        "\n",
        "# Histogram of pixel intensities\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(all_pixels, bins=50, color='steelblue', edgecolor='black')\n",
        "plt.title(\"Pixel Intensity Distribution\")\n",
        "plt.xlabel(\"Pixel Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "oEm6KZmrmuRM"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}